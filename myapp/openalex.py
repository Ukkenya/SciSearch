import requests

#–≤—Å–µ —Ä–∞–±–æ—Ç–∞–µ—Ç,—Ñ–∏–ª—å—Ç—Ä—ã –µ—Å—Ç—å,—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –µ—Å—Ç—å,–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –º–∏–Ω—É—Å - –º–∞–ª–æ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö, –ø–æ—ç—Ç–æ–º—É –ø–æ–∏—Å–∫ –Ω–∞ —Ä—É—Å—Å–∫–æ–º 50/50 —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π
def search_openalex(query, per_page=5, from_year=None, to_year=None,
                    source_type=None, language=None, sort_by=None):

    url = "https://api.openalex.org/works"
    params = {
        "search": query,
        "per_page": per_page,
        "mailto": "scisearch058@gmail.com"
    }


    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
    filters = []
    if from_year or to_year:
        year_filter = []
        if from_year:
            year_filter.append(f"from_publication_date:{from_year}-01-01")
        if to_year:
            year_filter.append(f"to_publication_date:{to_year}-12-31")
        filters.append(",".join(year_filter))

    if source_type:
        filters.append(f"type:{source_type}")

    if language:
        filters.append(f"language:{language}")

    if filters:
        params["filter"] = ",".join(filters)

    try:
        response = requests.get(url, params=params)
        response.raise_for_status()
        data = response.json()

        total_count = data.get("meta", {}).get("count", 0)
        results = data.get("results", [])

        print(f"\nüîç –ù–∞–π–¥–µ–Ω–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤—Å–µ–≥–æ: {total_count}")
        print(f"üìÑ –ü–æ–∫–∞–∑–∞–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)}\n")

        if not results:
            print(f"–ü–æ –∑–∞–ø—Ä–æ—Å—É '{query}' –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            return []

        # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏
        articles_data = []
        for work in results:
            article = {
                "title": work.get("title", "–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è"),
                "authors": [a['author']['display_name'] for a in work.get("authorships", [])],
                "year": work.get("publication_year", None),
                "abstract": get_abstract(work),
                "url": work.get("id", None),
                "source_type": work.get("type", None),
                "language": work.get("language", None)
            }
            articles_data.append(article)

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if sort_by == 'author':
            articles_data.sort(key=lambda x: x['authors'][0] if x['authors'] else "")
        elif sort_by == 'year':
            articles_data.sort(key=lambda x: x['year'] if x['year'] else 0, reverse=True)

        return articles_data

    except requests.exceptions.RequestException as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}")
        return []


def get_abstract(work):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é –∏–∑ —Ä–∞–±–æ—Ç—ã"""
    abstract_inv = work.get("abstract_inverted_index")
    if abstract_inv:
        return ' '.join(sorted(abstract_inv.keys(), key=lambda x: min(abstract_inv[x])))
    return work.get("abstract", "–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")


query1 = "–∏–∏ –≤ –º–µ–¥–∏—Ü–∏–Ω–µ"
# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
articles = search_openalex(
    query1,
    per_page=3,
    #source_type="article",
    language="ru",
    sort_by='year'
)

# –¢–µ–ø–µ—Ä—å articles —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏
"""for article in articles:
    print(f"–ù–∞–∑–≤–∞–Ω–∏–µ: {article['title']}")
    print(f"–ê–≤—Ç–æ—Ä—ã: {', '.join(article['authors'])}")
    print(f"–ì–æ–¥ –∏–∑–¥–∞–Ω–∏—è: {article['year']}")
    print(f"–ê–Ω–Ω–æ—Ç–∞—Ü–∏—è: {article['abstract']}")
    print(f"–°—Å—ã–ª–∫–∞: {article['url']}")
    print('-'*80+'\n')"""

